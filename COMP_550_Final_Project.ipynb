{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COMP 550 Final Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "VFxbkkdA20oD",
        "53zcybmlHX9U",
        "BUi3ydrq_l6E"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seb19283/COMP550-Final-Project/blob/main/COMP_550_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import gzip\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np "
      ],
      "metadata": {
        "id": "tAJCtxFw29Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Margot"
      ],
      "metadata": {
        "id": "VFxbkkdA20oD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve31ATiQcmnt"
      },
      "source": [
        "def run_margot(text):\n",
        "  data = {'text': text}\n",
        "  headers = {'content-type': 'application/json'}\n",
        "  response = requests.post('https://penelope.vub.be/margot-api/track-arguments', json=data, headers=headers)\n",
        "  return response.text\n",
        "\n",
        "def margot_to_json(response):\n",
        "  return json.loads(response)['document']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMDb Dataset"
      ],
      "metadata": {
        "id": "0X-Y70PFHRhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this is processed similar to amazon\n",
        "IMDB_file = 'https://raw.githubusercontent.com/seb19283/COMP550-Final-Project/main/margot.json'\n",
        "IMDB = pd.read_json(IMDB_file,orient = 'values',lines=True)\n",
        "IMDB"
      ],
      "metadata": {
        "id": "GExiBfWkHWMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Margot Vec"
      ],
      "metadata": {
        "id": "BUi3ydrq_l6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# MARGOT Feature Vectorization [avg_claim, avg_evidence, max_claim, max_evidence, pctg_c_over0, pctg_e_over0]\n",
        "\n",
        "def margot_Vec(dataframe):\n",
        "  v = np.zeros((len(dataframe),8))\n",
        "  for i in range(len(dataframe)):\n",
        "    d = pd.DataFrame(dataframe[\"margot\"][i])\n",
        "    if d.empty:\n",
        "      v[i] = [0] * 8\n",
        "      continue\n",
        "  \n",
        "    avg_claim = np.average(d[\"claim_score\"])\n",
        "    avg_evidence = np.average(d[\"evidence_score\"])\n",
        "    max_claim = np.max(d[\"claim_score\"])\n",
        "    max_evidence = np.max(d[\"evidence_score\"])\n",
        "    num_c_over0 = np.sum(d[\"claim_score\"] > 0)\n",
        "    num_e_over0 = np.sum(d[\"evidence_score\"] > 0)\n",
        "    pctg_c_over0 = np.sum(d[\"claim_score\"] > 0) / len(d)\n",
        "    pctg_e_over0 = np.sum(d[\"evidence_score\"] > 0 ) / len(d)\n",
        "\n",
        "    v[i] = [avg_claim,avg_evidence,max_claim,max_evidence,num_c_over0,num_e_over0,pctg_c_over0,pctg_e_over0]\n",
        "  return v \n",
        "\n",
        "amazon_vec = margot_Vec(amazon)\n",
        "IMDB_vec = margot_Vec(IMDB)"
      ],
      "metadata": {
        "id": "y4raEr1ebrPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "def appendVec(target, vec):\n",
        "  return scipy.sparse.hstack((target,vec))"
      ],
      "metadata": {
        "id": "nrqrevNADoNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n"
      ],
      "metadata": {
        "id": "Ka-VIzX86591"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# returns encodings of text without margot vec including (BOW,Tfidf,Bernoulli)\n",
        "def transform_frame(dataframe,textName):\n",
        "  Count_Vectorizer = CountVectorizer(ngram_range=(2,2),stop_words='english')\n",
        "  Tfidf_Vectorizer = TfidfVectorizer(ngram_range=(2,2),stop_words='english')\n",
        "  bayes_Vectorizer = CountVectorizer(ngram_range=(2,2),stop_words='english',binary=True)\n",
        "  X_bag = Count_Vectorizer.fit_transform(dataframe[textName])\n",
        "  X_Tfidf = Tfidf_Vectorizer.fit_transform(dataframe[textName])\n",
        "  X_bayes = bayes_Vectorizer.fit_transform(dataframe[textName])\n",
        "  return (X_bag,X_Tfidf,X_bayes)"
      ],
      "metadata": {
        "id": "0ljPyhO868W9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = transform_frame(IMDB,\"review\")"
      ],
      "metadata": {
        "id": "bDdS5h7q-yCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper para\n",
        "IMDB_useful_threshold = 0.5\n",
        "Y_IMDB = [0 if x < IMDB_useful_threshold else 1 for x in IMDB[\"helpfulness\"]]"
      ],
      "metadata": {
        "id": "bMWHm97Tp45F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ones = 0\n",
        "zeros = 0\n",
        "\n",
        "for (i, x) in enumerate(Y_IMDB):\n",
        "  if x == 1:\n",
        "    ones += 1\n",
        "  else:\n",
        "    zeros += 1\n",
        "\n",
        "print(ones, zeros)"
      ],
      "metadata": {
        "id": "-DZzMTyeyLzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import random\n",
        "import sys\n",
        "def eval(X,Y,model,random_state):\n",
        "    x_train,x_test,y_train,y_test = train_test_split(X,Y,train_size=0.8,random_state=random_state) #80% train, 25% test\n",
        "    model = model().fit(x_train,y_train)\n",
        "    y_predict = model.predict(x_test)\n",
        "    f1 = f1_score(y_test,y_predict)\n",
        "    acc = accuracy_score(y_test, y_predict)\n",
        "    rec = recall_score(y_test, y_predict)\n",
        "    prec = precision_score(y_test, y_predict,zero_division=1)\n",
        "    return f1, acc, rec, prec\n",
        "\n",
        "def report_and_apply_margot(model,dataset_Name,x,label,margot_vec):\n",
        "\n",
        "  random_state = random.randint(0,2**32 - 1 )\n",
        "  print(f\"{type(model()).__name__}  on {dataset_Name} margot ONLY. Result(f1,acc,rec,prec) : {eval(margot_vec,label,model,random_state)}\")\n",
        "  print(f\"{type(model()).__name__}  on {dataset_Name}. Result(f1,acc,rec,prec) : {eval(x,label,model,random_state)}\")\n",
        "  print(f\"{type(model()).__name__}  on {dataset_Name} with margot. Result(f1,acc,rec,prec) : {eval(appendVec(x,margot_vec),label,model,random_state)}\")\n",
        "  \n",
        "\n",
        "def getResult(encodings,label,dataset_Name,margot_vec):\n",
        "  X_bag,X_Tfidf,X_bayes = encodings\n",
        "\n",
        "  report_and_apply_margot(LogisticRegression,dataset_Name+\"BOW\",X_bag,label,margot_vec)\n",
        "  report_and_apply_margot(LogisticRegression,dataset_Name+\"Tfidf\",X_Tfidf,label,margot_vec)\n",
        "  print()\n",
        "  report_and_apply_margot(MultinomialNB,dataset_Name+\"BOW\",X_bag,label,MinMaxScaler().fit_transform(margot_vec))\n",
        "  report_and_apply_margot(MultinomialNB,dataset_Name+\"Tfidf\",X_Tfidf,label,MinMaxScaler().fit_transform(margot_vec))\n",
        "  print()\n",
        "  report_and_apply_margot(RandomForestClassifier,dataset_Name+\"BOW\",X_bag,label,margot_vec)\n",
        "  report_and_apply_margot(RandomForestClassifier,dataset_Name+\"Tfidf\",X_Tfidf,label,margot_vec)\n",
        "  print()\n",
        "  report_and_apply_margot(MLPClassifier,dataset_Name+\"BOW\",X_bag,label,margot_vec)\n",
        "  report_and_apply_margot(MLPClassifier,dataset_Name+\"Tfidf\",X_Tfidf,label,margot_vec)\n",
        "\n"
      ],
      "metadata": {
        "id": "DMAMAiPo69It"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "getResult(b,Y_IMDB,\"IMDB\",IMDB_vec)"
      ],
      "metadata": {
        "id": "CLVWim3lS347"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}